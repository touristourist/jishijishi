叙述基础VAE的理论

flow 模型在VAE中的应用



dense-vae

conv-vae

pixel-vae

resnet-vae

[一](https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247490358&idx=1&sn=b4b5d6014bdd365456d500537ba5bcad&chksm=96e9c4b6a19e4da08710a55935dc2e15b00838d5395fdf2a424c50dedff9af7fa11441741b9d&scene=21#wechat_redirect) [二](https://zhuanlan.zhihu.com/p/41912710) [三](https://kexue.fm/archives/5776) [四](https://kexue.fm/archives/5807) [五](https://blog.csdn.net/daydayjump/article/details/85041564)

Real Nvp



### note：

VAE优化的是对数似然的下界，这样可以使得对数似然不会太差

https://zhuanlan.zhihu.com/p/41912710

生成模型的本质，就是希望用一个我们知道的概率模型来拟合所给的数据样本，也就是说，我们得写出一个带参数 θ 的分布 qθ(x)。然而，我们的神经网络只是“万能函数拟合器”，却不是“万能分布拟合器”，也就是它原则上能拟合任意函数，但不能随意拟合一个概率分布，因为概率分布有“非负”和“归一化”的要求。

积分$q(x)=\int q(z)q(x|z)dz$   可以拟合任意分布，其中，$q(z)$ 和$q(x|z)$一般是高斯分布

$q_\theta(x|z)$中的$\theta$ 指的是分布中的参数，如高斯分布中的参数是（$\mu$ ,$\sigma^2$）(一维)

对于分布，衡量分布拟合的好坏，使用对数似然去衡量 ,假设真实数据分布为 p̃(x)，那么我们就需要最大化目标：$E_{x\sim p̃(x)}[log(q_\theta(x))]​$

VAE 和 GAN 在不同方向上避开了这个困难。VAE **没有直接优化对数似然**，而是优化一个更强的下界，这使得它只能是一个近似模型，无法达到良好的生成效果。GAN 则是通过一个交替训练的方法绕开了这个困难，确实保留了模型的精确性，所以它才能有如此好的生成效果。



 

https://blog.csdn.net/SweetSeven_/article/details/80820945

![](./pic/vae_procedure.png)

VAE的过程如上，**x是样本观测到的数据**，有n维（对于mnist数据集来说，一张图片的数据相当于有28*28=784维），我们的假设是x由隐变量z产生，由z->x就是VAE中的生成模型(类似解码器)$p_\theta(x|z)$，而由x->z就是识别模型（类似编码器）$q_\phi(z|x)$。

我们要训练的就是生成模型$p_\theta(x|z)$ 当得到训练后的$p_\theta(x|z)​$  就可以用来生成新的图像。

VAE是用识别模型$q_\phi(z|x)$ 去逼近真实的后验概率$p_\theta (z|x)​$ 使用KL散度衡量两个分布的相似程度

![](./pic/KL-infer.png)

所以对数极大似然又有如下等式

![](./pic/log-likelihood.png)

KL-divergence取值非负，所以导出变分下界:

![](./pic/VAE-elbo.png)

### 优化变分下界

这样通过优化变分下界，就能提高对数似然的下限，从而优化模型。所以最终的优化对象从对数似然函数（$\Sigma$ )转为优化：

![](./pic/optimize-object.png)

根据变分下界的关系式，用MC方法抽样估计，可以从两种方法得到该变分下界的估计值：

第一种方法用到了前述的变分下届原公式：

![](./pic/lowerBound-estimate-A.png)

![](./pic/lowerBound-estimate-B.png)

而对于总的变分下界，当样本集中的样本数量N很大的时候，采用mini-batch方法，其中M相当于Batch-size.。当外层M较大时，内层的L就可以选小些。

![](./pic/mini-batch.png)

实验中假设的各分布为：

![](./pic/value-assigned.png)

而对于**生成模型**$p_\theta (x_i|z)$ 的选取根据样本数据的形式有Bernoulli和Gaussion两种分布选择

![](./pic/px_z-Ber.png)

![](./pic/px_z-Gau.png)



$P_\theta (z)​$是先验分布，一开始假设为Gaussian，而在出现样本X后，会有后验分布$P_\theta(z|x)​$  是后验分布，此处用$q_\phi(z|x)​$ 去近似，$P_\theta(x|z)​$  是最终的生成模型。

 

[链接](http://skyhigh233.com/blog/2018/04/05/vae/)

### **重参数技巧**

在endoder阶段，对于z的采样，是先得到$p_\theta() $ 的参数（mean，log std），然后在N(0,1)标准正态分布中取样一点$\epsilon$ （$\epsilon ​$相当于**噪声**）然后z=μ+σ⊙ϵ,ϵ∼N(0,1)z=μ+σ⊙ϵ,ϵ∼N(0,1) 得到z的取样值。



在decoder阶段，直接将Encoder后得到的隐变量z经过生成模型$p_\theta (x|z)$神经网络，得到输出值。（如果是离散的，则可以经过softmax进行预测，最后计算cross entropy；否则可以直接算MSE）。



计算loss：

包括生成图像和原图像的误差，以及**KL散度**（KL散度是为了让Z向Gaussion 分布靠，防止退化成方差为0的分布（确定值z=$\mu​$ ）这也是变分编码器和普通编码器的区别，使得其能够生成新的图片）  ，下式可以当作误差函数loss
$$
L(θ,ϕ;x(i))=KL(qϕ(z∣x(i))∥pθ(z))−Ez∼qϕ(z∣x(i))(logpθ(x(i)∣z))
$$








###### [解析流生成模型「Glow」](https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247490358&idx=1&sn=b4b5d6014bdd365456d500537ba5bcad&chksm=96e9c4b6a19e4da08710a55935dc2e15b00838d5395fdf2a424c50dedff9af7fa11441741b9d&scene=21#wechat_redirect)

**生成模型：**

**VAE：**

VAE 是在 Autoencoder 的基础上让图像编码的潜在向量服从高斯分布从而实现图像的生成，**优化了数据对数似然的下界**，VAE 在图像生成上是可并行的， 但是 VAE 存在着生成图像模糊的问题，Glow 文中称之为优化相对具有挑战性。

**GAN：**

GAN 的思想就是利用博弈不断的优化生成器和判别器从而使得生成的图像与真实图像在分布上越来越相近。GAN 生成的图像比较清晰， 在很多 GAN 的拓展工作中也取得了很大的提高。但是 GAN 生成中的多样性不足以及训练过程不稳定是 GAN 一直以来的问题，同时 GAN 没有潜在空间编码器，从而缺乏对数据的全面支持。

它没有编码器，所以数据点不能在潜在空间中被表示。

**Autoregressive Model**:

自回归模型在 **PixelCNN 和 PixelRNN** 上展示了很不错的实验效果，但是由于是按照像素点去生成图像导致计算成本高， 在可并行性上受限，在处理大型数据如大型图像或视频是具有一定麻烦的。它可逆但是不能并行。 



基于流的生成模型：

NICE（NON-LINEAR INDEPENDENT COMPONENTS ESTIMATION）

RealNVP





flow是想办法得到一个encoder将输入x编码为隐变量z，并且使得z服从标准正态分布。得益于flow模型的精巧设计，这个encoder是可逆的，从而我们可以立马从encoder写出相应的decoder（生成器）出来，因此，只要encoder训练完成，我们就能同时得到decoder，完成生成模型的构建。



> realNVP它一般化了耦合层，并成功地在耦合模型中引入了卷积层，使得可以更好地处理图像问题。更进一步地，它还提出了多尺度层的设计，这能够降低计算量，通过还提供了强大的正则效果，使得生成质量得到提升。至此，flow模型的一般框架开始形成。



耦合层：加性耦合，乘性耦合









































## 阅读记录



### [**关于极大似然估计（MLE），对数似然理解**](https://zhuanlan.zhihu.com/p/32803109)

> 什么是模型的参数：
>
> 最大似然估计（**MLE**，maximum likelihood estimates）的直观解释： 找到这样一组参数，使得此时模型最有可能（概率最大）产生真实观察数据



对于样本中的数据，我们认为每个数据的产生都是独立的，假设我们用高斯分布
$$
P(x; \mu,\sigma)=\frac{1}{\sigma \sqrt {2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$
  拟合数据的分布，那么如何描述在参数$\mu​$ ，$\theta​$ 下拟合的“好坏”，答案是算出产生这些数据的联合概率，由于这些数据是独立的，所以联合概率就等于边缘概率之积。

所以如果数据集中只有数据点9，9.5，11，那么计算

​                                        $P(9,9.5,10; \mu,\sigma)=P(9; \mu,\sigma) \times P(9.5; \mu,\sigma) \times P(11; \mu,\sigma)$

只要找到使得上式最大的参数就找到了最好估计的模型，就找到了**极大似然**。



> 为什么要用**对数极大似然？**
>
>   一般求最值的方法是求导微分，但是上式难微分，**所以取对数简化**
>
> **最大似然估计总是能精确地得到解吗？**
>
> 简单来说，不能。更有可能的是，在真实的场景中，**对数似然函数的导数仍然是难以解析**的（也就是说，很难甚至不可能人工对函数求微分）。因此，**一般采用期望最大化（EM）算法等迭代方法为参数估计找到数值解**，但总体思路还是一样的。
>
> **$L(\mu,\sigma;data)和P(data;\mu,\sigma)的区别​$** ：
>
>  P(data; μ, σ) 它的意思是「在模型参数μ、σ条件下，观察到数据 data 的概率」。值得注意的是，我们可以将其推广到任意数量的参数和任何分布。
>
> 另一方面，L(μ, σ; data) 的意思是「我们在观察到一组数据 data 之后，参数 μ、σ 取特定的值的似然度。」在这里参数是不确定的，要求的是一组参数使得对data的估计似然最大。



关于贝叶斯定理

> **贝叶斯定理**
>
> 贝叶斯定理的意义在于使我们能**利用已有的知识或信念（通常称为先验的）帮助计算相关事件的概率**。例如，如果想知道在炎热和晴朗的天气中卖出冰淇淋的概率，贝叶斯定理可以使用「在其它类型天气中可能卖出冰淇淋数量」的先验知识。先验知识本身并不是完全客观的，可能带有主观成分，甚至是完全的猜测。而这也会对最终的条件概率计算产生影响.



https://zhuanlan.zhihu.com/p/32803109

**贝叶斯定理的模型形式**
$$
P(\Theta|data)=\frac{P(data|\Theta) \times P(\Theta)}{P(data)}​
$$
Θ是我们感兴趣的，它代表了参数的集合。因此如果要估计高斯分布的参数值，那么Θ代表了平均值μ和标准差σ，用数学形式表示为Θ = {μ, σ}。

data 或 y={y1, y2, …, yn} ，它代表了观察数据的集合.

**P(Θ) 是先验分布**，它代表了我们相信的参数值分布(这个分布是由经验或主观得到的，也是预先知道的)。等式左边的 **P(Θ|data) 称为后验分布**，它代表利用观察数据计算了等式右边之后的参数值分布。**而 P(data| Θ) 和似然度分布类似，表示的是将已有的数据套用在某个<u>已经确定了参数</u>的模型上计算出的似然**。   我们只对参数的分布感兴趣，而 P(data) 对此并没有任何参考价值，所以可以忽略，甚至上述公式可以写成：                                                         
$$
P(\Theta|data) \propto {P(data|\Theta) \times P(\Theta)}
$$
解释：$P(\theta )$是参数的先验分布，（横坐标是$\theta$ ，纵坐标是概率，就是pdf函数），当$\theta​$ 取特定值时，就是一个特定的数。



**最大后验估计(MAP)**

由先验和极大似然的乘积得到贝叶斯定理的后验分布后，可以用分布的期望，众数估计MAP





**当我们获取新数据，会发生什么？**

贝叶斯推理的最大优势之一是使用它无需有大量数据。事实上贝叶斯框架允许你有数据后**实时、迭代地更新你的信念**。其工作如下：你有一个关于什么的先验信念（比如参数值），接着你接收到一些数据。你可以通过计算后验分布更新你的信念，就像上面我们做的那样。随后，甚至有更多的数据进来。因此我们的后验成为新的先验。我们可以通过从新数据中获得的似然更新的新的先验，并再次获得一个新后验。这一循环可无限持续，因此你可以不断更新你的信念。

卡尔曼过滤器（及其变体）是很好的一个实例。它在很多场景中使用，可能数据科学中最醒目就是其在自动驾驶汽车上的应用。在我的数学蛋白质晶体学博士学位期间，我曾使用一种名为 Unscented 卡尔曼过滤器的变体，并为实现它们的开源软件包做出了贡献。为了更好地视觉描述卡尔曼过滤器，请查看 Tim Babb 的这篇文章：[http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/](https://link.zhihu.com/?target=http%3A//www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/)。







### [MLE和MAP解释](https://zhuanlan.zhihu.com/p/32480810)

![](./pic/MLE-infer.png)

上述式子中的arg max求的是使得P(X;$\theta$ )最大时的参数（arg）集合。

最后这一行所优化的函数被称为Negative Log Likelihood (NLL)。 NLL的最小值和MLE极大似然估计的最大值是相同的

![](./pic/MAP-infer.png)

上述推导对应如下贝叶斯公式：
$$
P(\Theta|data)=\frac{P(data|\Theta) \times P(\Theta)}{P(data)}
$$
![](./pic/MAP-about.png)

**补充：**

当先验分布P($\theta$ )是[0,1]上的均匀分布时，MAP和MLE相等

由上述推导公式也可以得出，MLE可以看作是一种特殊的MAP